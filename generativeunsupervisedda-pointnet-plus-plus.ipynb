{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6766670,"sourceType":"datasetVersion","datasetId":3894335},{"sourceId":6766707,"sourceType":"datasetVersion","datasetId":3894357},{"sourceId":6828233,"sourceType":"datasetVersion","datasetId":3926326},{"sourceId":6828382,"sourceType":"datasetVersion","datasetId":3926409},{"sourceId":7006568,"sourceType":"datasetVersion","datasetId":4027929}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport h5py\nimport numpy \nimport random\nimport math\nimport shutil\nfrom tqdm import tqdm\nfrom path import Path\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:50\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"SAMPLE_POINTS = 2000\nCLASSESS_CNT = 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Device","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# device = \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"class Normalize(object):\n    def __call__(self, pointcloud):\n        norm_pointcloud = pointcloud - numpy.mean(pointcloud, axis=0)\n        norm_pointcloud /= numpy.max(numpy.linalg.norm(norm_pointcloud, axis=1))\n        return  norm_pointcloud\n    \nclass RandomNoise(object):\n    def __call__(self, pointcloud):\n        noise = numpy.random.normal(0, 0.02, (pointcloud.shape))\n        noisy_pointcloud = pointcloud + noise\n        return  noisy_pointcloud\n    \nclass RandomScale(object):\n    def __call__(self, pointcloud):\n        s = numpy.random.uniform(0.9, 1.1, 3)\n        rot_mat = numpy.array([[s[0], 0, 0],\n                            [0, s[1], 0],\n                            [0, 0, s[2]]])\n        return numpy.matmul(pointcloud, rot_mat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def default_transforms():\n    return transforms.Compose([\n        Normalize(),\n        transforms.ToTensor()])\n\ndef default_transforms_no_normalize():\n    return transforms.Compose([transforms.ToTensor()])\n\ndef training_transforms():\n    return transforms.Compose([\n        Normalize(),\n        RandomNoise(),\n        RandomScale(),\n        transforms.ToTensor()])\n\ndef training_transforms_no_normalize():\n    return transforms.Compose([\n        RandomNoise(),\n        RandomScale(),\n        transforms.ToTensor()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Part Instance Utility Function","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport plotly.io as pio\n\ndef visualize_point_cloud(point_cloud, labels, export_svg=False, filename='point_cloud.svg'):\n    trace = go.Scatter3d(\n        x=point_cloud[:, 0],\n        y=point_cloud[:, 1],\n        z=point_cloud[:, 2],\n        mode='markers',\n        marker=dict(size=5, color=labels, colorscale='Viridis', opacity=0.5),\n    )\n\n    data = [trace]\n\n    layout = go.Layout(\n        scene=dict(\n            xaxis=dict(visible=False, showbackground=False),\n            yaxis=dict(visible=False, showbackground=False),\n            zaxis=dict(visible=False, showbackground=False),\n        ),\n        paper_bgcolor='rgba(0,0,0,0)',\n        plot_bgcolor='rgba(0,0,0,0)'\n    )\n\n    fig = go.Figure(data=data, layout=layout)\n    \n    if export_svg:\n        pio.write_image(fig, filename, format='svg')\n    else:\n        pio.show(fig)\n\n# Example usage\n# visualize_point_cloud(point_cloud, labels, export_svg=True, filename='point_cloud.svg')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class GenerativeJawDataset(Dataset):\n    def __init__(self, npy_file_path=\"/kaggle/input/generative-jaw/generative.npy\", transform=training_transforms()):\n        self.data = numpy.load(npy_file_path)\n        self.transform = transform\n\n    def __len__(self):\n        return (self.data).shape[0]\n\n    def __getitem__(self, idx):\n        itemdata = self.data[idx]\n        pointcloud = numpy.column_stack((itemdata[:,0], itemdata[:,1], itemdata[:,2]))\n        label = itemdata[:,3] \n        d = 1  # d = 1, as it has annotations\n        pointcloud = self.transform(pointcloud)\n        pointcloud = pointcloud[0]\n        \n        lower = 1\n        if idx >= 10: lower = 0\n            \n        assert pointcloud.shape[0] == SAMPLE_POINTS\n        assert pointcloud.shape[1] == 3\n        \n        del itemdata\n        torch.cuda.empty_cache()\n\n        return pointcloud.type(torch.FloatTensor), torch.tensor(label).type(torch.LongTensor), torch.tensor(d).type(torch.LongTensor), torch.tensor(lower).type(torch.LongTensor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestJawDataset(Dataset):\n    def __init__(self, npy_file_path=\"/kaggle/input/real-jaw-2000-pointcloud-annotated-classbased/test_jaw.npy\", transform=default_transforms()):\n        self.data = numpy.load(npy_file_path)\n        self.transform = transform\n\n    def __len__(self):\n        return 1 # TODO: Edit this later if we have more annotations\n\n    def __getitem__(self, idx):\n        itemdata = (self.data).astype(numpy.float32) # TODO: Edit this later if we have more annotations\n        pointcloud = itemdata[:, :3]  # Extract x, y, z columns\n        label = itemdata[:, 3] \n        d = 1  # d = 1, as it has annotations\n        pointcloud = self.transform(pointcloud)\n        pointcloud = pointcloud[0]\n        \n        if pointcloud.shape[0] > SAMPLE_POINTS:\n            pointcloud = pointcloud[:2000]\n            label = label[:2000]\n        \n        if pointcloud.shape[0] < SAMPLE_POINTS:\n            pointcloud = torch.cat([pointcloud, pointcloud[-1].repeat(SAMPLE_POINTS-pointcloud.shape[0], 1)], dim=0)\n            label = torch.cat([label, label[-1].repeat(SAMPLE_POINTS-label.shape[0], 1)], dim=0)\n        \n        assert pointcloud.shape[0] == SAMPLE_POINTS\n        assert pointcloud.shape[1] == 3\n        \n        del itemdata\n        torch.cuda.empty_cache()\n\n        return pointcloud.type(torch.FloatTensor), torch.tensor(label).type(torch.LongTensor), torch.tensor(d).type(torch.LongTensor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RealJawDataset(Dataset):\n    def __init__(self, data_dir=\"/kaggle/input/real-jaw-2000-pointcloud/RealJaw2000\", transform=training_transforms()):\n        self.data_dir = data_dir\n        self.file_list = sorted(os.listdir(data_dir)[:20])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_list)\n    \n    def load_xyz_file(self, file_path):\n        with open(file_path, 'r') as f:\n            data = numpy.loadtxt(f, delimiter=' ')\n        return data\n\n    def __getitem__(self, idx):\n        file_path = os.path.join(self.data_dir, self.file_list[idx])\n\n        data = self.load_xyz_file(file_path)\n\n        # Load XYZ data from the file (assuming comma-delimited)\n        pointcloud = numpy.column_stack((data[:,0], data[:,1], data[:,2])).astype(numpy.float32)\n\n        # Create a fixed label (doesnt matter) and d (0)\n        label = torch.zeros(SAMPLE_POINTS, dtype=torch.int64)\n        d = torch.tensor(0, dtype=torch.int64)\n        \n        lower = idx%2\n        \n        pointcloud = self.transform(pointcloud)\n        pointcloud = pointcloud[0]\n        \n        if pointcloud.shape[0] > SAMPLE_POINTS:\n            pointcloud = pointcloud[:2000]\n        \n        if pointcloud.shape[0] < SAMPLE_POINTS :\n            pointcloud = torch.cat([pointcloud, pointcloud[-1].repeat(SAMPLE_POINTS-pointcloud.shape[0], 1)], dim=0)\n        \n        assert pointcloud.shape[0] == SAMPLE_POINTS\n        assert pointcloud.shape[1] == 3\n        \n        del file_path\n        del data\n        torch.cuda.empty_cache()\n\n        return pointcloud.type(torch.FloatTensor),label, d,torch.tensor(lower).type(torch.LongTensor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainingDataset(Dataset):\n    def __init__(self):\n        self.generative_dataset = GenerativeJawDataset()\n        self.real_dataset = RealJawDataset()\n\n    def __len__(self):\n        return len(self.generative_dataset) + len(self.real_dataset)\n\n    def __getitem__(self, idx):\n        if idx < len(self.real_dataset):\n            return self.real_dataset[idx]\n        else:\n            return self.generative_dataset[idx-len(self.real_dataset)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generative_dataset = GenerativeJawDataset()\ntest_dataset = TestJawDataset()\nreal_dataset = RealJawDataset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Real Data","metadata":{}},{"cell_type":"code","source":"data = real_dataset[18]\nvisualize_point_cloud(data[0], data[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Real Annotated Test Data","metadata":{}},{"cell_type":"code","source":"data = test_dataset[0]\n\nvisualize_point_cloud(data[0], data[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Generative Jaw Data With Annotations","metadata":{}},{"cell_type":"code","source":"data = generative_dataset[16]\nvisualize_point_cloud(data[0], data[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model: PointNet","metadata":{}},{"cell_type":"code","source":"class GradReverse(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output.neg()\n\ndef GRL(x):\n    return GradReverse.apply(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/yanx27/Pointnet_Pointnet2_pytorch.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Pointnet_Pointnet2_pytorch.models.pointnet2_utils import PointNetSetAbstraction, PointNetFeaturePropagation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sa1C = PointNetSetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=3, mlp=[64, 64, 128], group_all=False)\nsa1S = PointNetSetAbstraction(npoint=2000, radius=0.2, nsample=32, in_channel=6, mlp=[64, 64, 128], group_all=False)\nsa2 = PointNetSetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)\nsa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetPPClassHead(nn.Module):\n    def __init__(self,num_class=2, normal_channel=False):\n        super(PointNetPPClassHead, self).__init__()\n        in_channel = 6 if normal_channel else 3\n        self.normal_channel = normal_channel\n        self.sa1 = sa1C\n        self.sa2 = sa2\n        self.sa3 = sa3\n        self.fc1 = nn.Linear(1024, 512)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.drop1 = nn.Dropout(0.4)\n        self.fc2 = nn.Linear(512, 256)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.drop2 = nn.Dropout(0.4)\n        self.fc3 = nn.Linear(256, num_class)\n\n    def forward(self, xyz):\n        B, _, _ = xyz.shape\n        if self.normal_channel:\n            norm = xyz[:, 3:, :]\n            xyz = xyz[:, :3, :]\n        else:\n            norm = None\n        l1_xyz, l1_points = self.sa1(xyz, norm)\n        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n        x = l3_points.view(B, 1024)\n        x = GRL(x)\n        x = self.drop1(F.relu(self.bn1(self.fc1(x))))\n        x = self.drop2(F.relu(self.bn2(self.fc2(x))))\n        x = self.fc3(x)\n        x = F.log_softmax(x, -1)\n\n\n        return x, l3_points","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetPPSeghead(nn.Module):\n    def __init__(self, num_classes=4, normal_channel=False):\n        super(PointNetPPSeghead, self).__init__()\n        if normal_channel:\n            additional_channel = 3\n        else:\n            additional_channel = 0\n        self.normal_channel = normal_channel\n        self.sa1 = sa1S\n        self.sa2 = sa2\n        self.sa3 = sa3\n        self.fp3 = PointNetFeaturePropagation(in_channel=1280, mlp=[256, 256])\n        self.fp2 = PointNetFeaturePropagation(in_channel=384, mlp=[256, 128])\n        self.fp1 = PointNetFeaturePropagation(in_channel=137+additional_channel, mlp=[128, 128, 128])\n        self.conv1 = nn.Conv1d(128, 128, 1)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.drop1 = nn.Dropout(0.5)\n        self.conv2 = nn.Conv1d(128, num_classes, 1)\n\n    def forward(self, xyz, cls_label_one_hot):\n        # Set Abstraction layers\n        B,C,N = xyz.shape\n        if self.normal_channel:\n            l0_points = xyz\n            l0_xyz = xyz[:,:3,:]\n        else:\n            l0_points = xyz\n            l0_xyz = xyz\n        l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)\n        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n        \n        l1_xyz, l1_points = GRL(l1_xyz), GRL(l1_points)\n        l2_xyz, l2_points = GRL(l2_xyz), GRL(l2_points)\n        l3_xyz, l3_points = GRL(l3_xyz), GRL(l3_points)\n        \n        # Feature Propagation layers\n        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)\n        l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)\n        l0_points = self.fp1(l0_xyz, l1_xyz, torch.cat([cls_label_one_hot.unsqueeze(dim=1).repeat(1,3,1),l0_xyz,l0_points],1), l1_points)\n        # FC layers\n        feat =  F.relu(self.bn1(self.conv1(l0_points)))\n        x = self.drop1(feat)\n        x = self.conv2(x)\n        x = F.log_softmax(x, dim=1)\n        x = x.permute(0, 2, 1)\n        return x, l3_points","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetDomainAdaptationModel(nn.Module):\n    def __init__(self, m=4, k1=2, k2=2):\n        super(PointNetDomainAdaptationModel,self).__init__()\n\n        self.m = m\n        self.k1 = k1\n        self.k2 =k2\n        \n        # Backbone\n        self.domain_classifier = PointNetPPClassHead(num_class=k1)\n        self.lower_upper_classifier = PointNetPPClassHead(num_class=k2)\n        self.segmentation_head = PointNetPPSeghead(num_classes=self.m,)\n\n    def forward(self, x, cls_label):\n        d_hat, d_trans_feat = self.domain_classifier(x)\n        l_hat, l_trans_feat = self.lower_upper_classifier(x)\n        seg_hat, seg_trans_feat = self.segmentation_head(x,cls_label)\n        return d_hat, d_trans_feat,l_hat, l_trans_feat, seg_hat, seg_trans_feat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dummpy = torch.randn(40,3,2000)\n# dumpyyy = torch.randn(40,2000)\n# model = PointNetDomainAdaptationModel()\n# model(dummpy,dumpyyy)\n# import gc\n# del dummpy\n# del dumpyyy\n# del model\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finally","metadata":{}},{"cell_type":"code","source":"training_dataset = TrainingDataset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(training_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PointNetDomainAdaptationModel(m=CLASSESS_CNT,k1=2, k2=2).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of trainable parameters\nnum_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(\"Number of trainable parameters:\", num_parameters)\n\n# Calculate the model size in megabytes (MB)\nmodel_size_mb = sum(p.numel() for p in model.parameters()) * 4 / (1024 ** 2)  # assuming 4 bytes per parameter\nprint(\"Model size:\", model_size_mb, \"MB\")\n\n# Calculate the size of the model's state dictionary in megabytes (MB)\nmodel_state_dict_size_mb = sum(p.numel() for p in model.state_dict().values()) * 4 / (1024 ** 2)\nprint(\"Model state dictionary size:\", model_state_dict_size_mb, \"MB\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetSegLoss(torch.nn.Module):\n    def __init__(self):\n        super(PointNetSegLoss, self).__init__()\n        self.cross_entropy_loss = nn.CrossEntropyLoss()\n\n    def forward(self, pred, target, trans_feat):\n        loss = self.cross_entropy_loss(pred, target)\n        return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetClassLoss(torch.nn.Module):\n    def __init__(self):\n        super(PointNetClassLoss, self).__init__()\n        \n        self.cross_entropy_loss = nn.CrossEntropyLoss()\n\n    def forward(self, pred, target, trans_feat):\n        loss = self.cross_entropy_loss(pred, target)\n        return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TotalLoss(nn.Module):\n    def __init__(self):\n        super(TotalLoss, self).__init__()\n        \n        # Lossess\n        self.seg_loss = PointNetSegLoss()  \n        self.class_loss = PointNetClassLoss()\n\n    def forward(self, d_hat, d, d_A_feat,l_hat, l, l_A_feat, seg_hat, seg, seg_A_feat, domain_adapation_factor=0.5):        \n        segmentation_loss = self.seg_loss(seg_hat, seg, seg_A_feat)\n        domain_classification_loss = self.class_loss(d_hat, d, d_A_feat)\n        label_classification_loss = self.class_loss(l_hat, l, l_A_feat)\n        total_loss = d*segmentation_loss + domain_classification_loss + label_classification_loss\n        total_loss = total_loss.mean()\n        return total_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_iou(predictions, targets):\n    intersection = (predictions & targets).sum()\n    union = (predictions | targets).sum()\n    iou = intersection / union\n    return iou","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"highest_iou = 0.0\ndef test(dataloader, model, loss_function):\n    global highest_iou\n    model.eval()\n    total_iou = 0.0\n    total_batches = len(dataloader)\n    \n    with torch.no_grad():\n        for batch, data in enumerate(tqdm(dataloader)):\n            pointcloud, label, d = (data[0].permute(0, 2, 1)).to(device), data[1].to(device), data[2].to(device)\n\n            # Get Scores\n            d_hat, d_trans_feat,l_hat, l_trans_feat, seg_hat, seg_trans_feat = model(pointcloud,torch.zeros_like(label).to(device))\n\n            predicted = torch.argmax(seg_hat, dim=2)\n\n            # Calculate the IoU score for this batch\n            iou = calculate_iou(predicted, label)\n\n            total_iou += iou.item()\n            \n            # Clean memory\n            del pointcloud\n            del label\n            del d\n            del d_hat\n            del d_trans_feat\n            del l_hat\n            del l_trans_feat\n            del seg_hat\n            del seg_trans_feat\n            del iou\n            del predicted\n            gc.collect()\n            torch.cuda.empty_cache()\n            \n    average_iou = total_iou / total_batches\n    if average_iou >= highest_iou:\n        highest_iou = average_iou\n        torch.save(model.state_dict(), \"/kaggle/working/model_state_highest.pth\")\n    print(\"Average IoU: \" + str(average_iou))\n    print(\"\")\n    print(\"Highest IoU: \" + str(highest_iou))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, optimizer, loss_function):\n    torch.cuda.empty_cache()\n    size = len(dataloader.dataset)\n    model.train()\n    loss_tot = 0.0\n    num = 0\n    for batch, data in enumerate(tqdm(dataloader)):\n        pointcloud, label, d, l = (data[0].permute(0, 2, 1)).to(device), data[1].to(device), data[2].to(device), data[3].to(device)\n        \n        # Zeroing the gradients\n        optimizer.zero_grad()\n\n        number_of_parts = CLASSESS_CNT\n        seg = torch.nn.functional.one_hot(label, number_of_parts).type(torch.FloatTensor).to(device)\n\n        # Get Scores\n        d_hat, d_trans_feat,l_hat, l_trans_feat, seg_hat, seg_trans_feat = model(pointcloud, torch.zeros_like(label).to(device))\n\n        # Calculate Loss\n        loss = loss_function(d_hat, d, d_trans_feat,l_hat, l, l_trans_feat, seg_hat, seg, seg_trans_feat)\n\n        # Backpropagation\n        loss.backward()\n\n        # Update\n        optimizer.step()\n        \n        loss_tot += loss.item()\n        num += 1\n        \n        # Clean memory\n        del pointcloud\n        del label\n        del d\n        del l\n        del number_of_parts\n        del seg\n        del d_hat\n        del d_trans_feat\n        del l_hat\n        del l_trans_feat\n        del seg_hat\n        del seg_trans_feat\n        del loss\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n#     loss_tot /= num\n    print(f'training loss: {(loss_tot):>0.5f}')\n    return loss_tot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_single_test_data(dataloader, model):\n    model.eval()\n    with torch.no_grad():\n        for batch, data in enumerate(tqdm(dataloader)):\n            pointcloud, label, d = (data[0].permute(0, 2, 1)).to(device), data[1].long().to(device), data[2].long().to(device)\n            # Get Scores\n            d_hat, d_trans_feat,l_hat, l_trans_feat, seg_hat, seg_trans_feat = model(pointcloud, label)\n            predicted = torch.argmax(seg_hat, dim=2).cpu()\n            \n            pointcloud_2 = pointcloud.clone().permute(0,2,1).cpu()\n            visualize_point_cloud(pointcloud_2[0], predicted[0])\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Hyperparameters\nepochs = 500\nbatch_size = 10\nlearning_rate = 1e-4\nmomentum=0.9\nweight_decay=0.5\n\n# Dataloader\ntraining_data_loader = DataLoader(training_dataset, batch_size, shuffle = True)\ntesting_dataloader = DataLoader(test_dataset, batch_size, shuffle = False)\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n# Loss \nloss_function = TotalLoss().to(device)\n\n# Scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', factor=0.1, patience=10, cooldown=5, min_lr=1e-4, verbose=True)\n\n# Training\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loss = train(training_data_loader, model, optimizer, loss_function)\n    test(testing_dataloader, model,loss_function )\n    scheduler.step(train_loss)\n    torch.save(model.state_dict(), \"/kaggle/working/model_state.pth\")\nprint(\"Done!\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Best Predictions","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/model_state_highest.pth\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_single_test_data(testing_dataloader, model)\n\ndata = test_dataset[0]\nvisualize_point_cloud(data[0], data[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}