{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6766670,"sourceType":"datasetVersion","datasetId":3894335},{"sourceId":6766707,"sourceType":"datasetVersion","datasetId":3894357},{"sourceId":6828233,"sourceType":"datasetVersion","datasetId":3926326},{"sourceId":6828382,"sourceType":"datasetVersion","datasetId":3926409}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport h5py\nimport numpy \nimport random\nimport math\nimport shutil\nfrom tqdm import tqdm\nfrom path import Path\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:45.359309Z","iopub.execute_input":"2023-11-19T15:17:45.359676Z","iopub.status.idle":"2023-11-19T15:17:48.845942Z","shell.execute_reply.started":"2023-11-19T15:17:45.359631Z","shell.execute_reply":"2023-11-19T15:17:48.844942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"SAMPLE_POINTS = 2000\nCLASSESS_CNT = 4","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:48.847998Z","iopub.execute_input":"2023-11-19T15:17:48.848828Z","iopub.status.idle":"2023-11-19T15:17:48.853268Z","shell.execute_reply.started":"2023-11-19T15:17:48.848791Z","shell.execute_reply":"2023-11-19T15:17:48.852267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Device","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# device = \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:48.854769Z","iopub.execute_input":"2023-11-19T15:17:48.855524Z","iopub.status.idle":"2023-11-19T15:17:48.896479Z","shell.execute_reply.started":"2023-11-19T15:17:48.855497Z","shell.execute_reply":"2023-11-19T15:17:48.895446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"class Normalize(object):\n    def __call__(self, pointcloud):\n        norm_pointcloud = pointcloud - numpy.mean(pointcloud, axis=0)\n        norm_pointcloud /= numpy.max(numpy.linalg.norm(norm_pointcloud, axis=1))\n        return  norm_pointcloud\n    \nclass RandomNoise(object):\n    def __call__(self, pointcloud):\n        noise = numpy.random.normal(0, 0.02, (pointcloud.shape))\n        noisy_pointcloud = pointcloud + noise\n        return  noisy_pointcloud\n    \nclass RandomScale(object):\n    def __call__(self, pointcloud):\n        s = numpy.random.uniform(0.9, 1.1, 3)\n        rot_mat = numpy.array([[s[0], 0, 0],\n                            [0, s[1], 0],\n                            [0, 0, s[2]]])\n        return numpy.matmul(pointcloud, rot_mat)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:49.482210Z","iopub.execute_input":"2023-11-19T15:17:49.482760Z","iopub.status.idle":"2023-11-19T15:17:49.489944Z","shell.execute_reply.started":"2023-11-19T15:17:49.482736Z","shell.execute_reply":"2023-11-19T15:17:49.489026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def default_transforms():\n    return transforms.Compose([\n        Normalize(),\n        transforms.ToTensor()])\n\ndef default_transforms_no_normalize():\n    return transforms.Compose([transforms.ToTensor()])\n\ndef training_transforms():\n    return transforms.Compose([\n        Normalize(),\n        RandomNoise(),\n        RandomScale(),\n        transforms.ToTensor()])\n\ndef training_transforms_no_normalize():\n    return transforms.Compose([\n        RandomNoise(),\n        RandomScale(),\n        transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:49.951079Z","iopub.execute_input":"2023-11-19T15:17:49.951353Z","iopub.status.idle":"2023-11-19T15:17:49.957410Z","shell.execute_reply.started":"2023-11-19T15:17:49.951331Z","shell.execute_reply":"2023-11-19T15:17:49.956298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Part Instance Utility Function","metadata":{}},{"cell_type":"code","source":"def visualize_point_cloud(point_cloud, labels, generative=False):\n    # Define a colormap for labels\n    colormap = plt.get_cmap(\"tab10\")  # You can choose any other colormap\n\n    trace = go.Scatter3d(\n        x=point_cloud[:, 0],\n        y=point_cloud[:, 1],\n        z=point_cloud[:, 2],\n        mode='markers',\n        marker=dict(size=5, color=labels, colorscale='Viridis', opacity=0.5),\n    )\n\n    data = [trace]\n\n    if True:\n        layout = go.Layout(\n            scene=dict(\n                xaxis=dict(title='X'),\n                yaxis=dict(title='Y'),\n                zaxis=dict(title='Z'),\n            )\n        )\n    else:\n        layout = go.Layout(\n            scene=dict(\n                xaxis=dict(title='X', range=(0,80)),\n                yaxis=dict(title='Y', range=(0,100)),\n                zaxis=dict(title='Z', range=(0,80)),\n            )\n        )\n        \n    fig = go.Figure(data=data, layout=layout)\n    pyo.init_notebook_mode(connected=True)\n    pyo.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:50.769542Z","iopub.execute_input":"2023-11-19T15:17:50.769816Z","iopub.status.idle":"2023-11-19T15:17:50.778119Z","shell.execute_reply.started":"2023-11-19T15:17:50.769794Z","shell.execute_reply":"2023-11-19T15:17:50.777182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class GenerativeJawDataset(Dataset):\n    def __init__(self, npy_file_path=\"/kaggle/input/generative-jaw/generative.npy\", transform=training_transforms()):\n        self.data = numpy.load(npy_file_path)\n        self.transform = transform\n\n    def __len__(self):\n        return (self.data).shape[0]\n\n    def __getitem__(self, idx):\n        itemdata = self.data[idx]\n        pointcloud = numpy.column_stack((itemdata[:,0], itemdata[:,1], itemdata[:,2]))\n        label = itemdata[:,3] \n        d = 1  # d = 1, as it has annotations\n        pointcloud = self.transform(pointcloud)\n        pointcloud = pointcloud[0]\n        \n        lower = 1\n        if idx >= 10: lower = 0\n            \n        assert pointcloud.shape[0] == SAMPLE_POINTS\n        assert pointcloud.shape[1] == 3\n        \n        del itemdata\n        torch.cuda.empty_cache()\n\n        return pointcloud.type(torch.FloatTensor), torch.tensor(label).type(torch.LongTensor), torch.tensor(d).type(torch.LongTensor), torch.tensor(lower).type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:17:55.644874Z","iopub.execute_input":"2023-11-19T15:17:55.645782Z","iopub.status.idle":"2023-11-19T15:17:55.654439Z","shell.execute_reply.started":"2023-11-19T15:17:55.645747Z","shell.execute_reply":"2023-11-19T15:17:55.653484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestJawDataset(Dataset):\n    def __init__(self, npy_file_path=\"/kaggle/input/real-jaw-2000-pointcloud-annotated-classbased/test_jaw.npy\", transform=default_transforms()):\n        self.data = numpy.load(npy_file_path)\n        self.transform = transform\n\n    def __len__(self):\n        return 1 # TODO: Edit this later if we have more annotations\n\n    def __getitem__(self, idx):\n        itemdata = (self.data).astype(numpy.float32) # TODO: Edit this later if we have more annotations\n        pointcloud = itemdata[:, :3]  # Extract x, y, z columns\n        label = itemdata[:, 3] \n        d = 1  # d = 1, as it has annotations\n        pointcloud = self.transform(pointcloud)\n        pointcloud = pointcloud[0]\n        \n        if pointcloud.shape[0] > SAMPLE_POINTS:\n            pointcloud = pointcloud[:2000]\n            label = label[:2000]\n        \n        if pointcloud.shape[0] < SAMPLE_POINTS:\n            pointcloud = torch.cat([pointcloud, pointcloud[-1].repeat(SAMPLE_POINTS-pointcloud.shape[0], 1)], dim=0)\n            label = torch.cat([label, label[-1].repeat(SAMPLE_POINTS-label.shape[0], 1)], dim=0)\n        \n        assert pointcloud.shape[0] == SAMPLE_POINTS\n        assert pointcloud.shape[1] == 3\n        \n        del itemdata\n        torch.cuda.empty_cache()\n\n        return pointcloud.type(torch.FloatTensor), torch.tensor(label).type(torch.LongTensor), torch.tensor(d).type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:18:05.514120Z","iopub.execute_input":"2023-11-19T15:18:05.514947Z","iopub.status.idle":"2023-11-19T15:18:05.528077Z","shell.execute_reply.started":"2023-11-19T15:18:05.514902Z","shell.execute_reply":"2023-11-19T15:18:05.527100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RealJawDataset(Dataset):\n    def __init__(self, data_dir=\"/kaggle/input/real-jaw-2000-pointcloud/RealJaw2000\", transform=training_transforms()):\n        self.data_dir = data_dir\n        self.file_list = sorted(os.listdir(data_dir)[:20])\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_list)\n    \n    def load_xyz_file(self, file_path):\n        with open(file_path, 'r') as f:\n            data = numpy.loadtxt(f, delimiter=' ')\n        return data\n\n    def __getitem__(self, idx):\n        file_path = os.path.join(self.data_dir, self.file_list[idx])\n\n        data = self.load_xyz_file(file_path)\n\n        # Load XYZ data from the file (assuming comma-delimited)\n        pointcloud = numpy.column_stack((data[:,0], data[:,1], data[:,2])).astype(numpy.float32)\n\n        # Create a fixed label (doesnt matter) and d (0)\n        label = torch.zeros(SAMPLE_POINTS, dtype=torch.int64)\n        d = torch.tensor(0, dtype=torch.int64)\n        \n        lower = (idx%2 == 0)\n        \n        pointcloud = self.transform(pointcloud)\n        pointcloud = pointcloud[0]\n        \n        if pointcloud.shape[0] > SAMPLE_POINTS:\n            pointcloud = pointcloud[:2000]\n        \n        if pointcloud.shape[0] < SAMPLE_POINTS :\n            pointcloud = torch.cat([pointcloud, pointcloud[-1].repeat(SAMPLE_POINTS-pointcloud.shape[0], 1)], dim=0)\n        \n        assert pointcloud.shape[0] == SAMPLE_POINTS\n        assert pointcloud.shape[1] == 3\n        \n        del file_path\n        del data\n        torch.cuda.empty_cache()\n\n        return pointcloud.type(torch.FloatTensor),label, d,torch.tensor(lower).type(torch.LongTensor)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:25:57.052343Z","iopub.execute_input":"2023-11-19T15:25:57.052700Z","iopub.status.idle":"2023-11-19T15:25:57.066070Z","shell.execute_reply.started":"2023-11-19T15:25:57.052672Z","shell.execute_reply":"2023-11-19T15:25:57.065147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainingDataset(Dataset):\n    def __init__(self):\n        self.generative_dataset = GenerativeJawDataset()\n        self.real_dataset = RealJawDataset()\n\n    def __len__(self):\n        return (len(self.generative_dataset) + len(self.real_dataset))//2\n\n    def __getitem__(self, idx):\n        try:\n            if idx % 2 == 0:\n                return self.generative_dataset[idx // 2], self.real_dataset[idx]\n            else:\n                return self.generative_dataset[(idx - 1) // 2 + 10], self.real_dataset[idx]\n        except IndexError as e:\n            # Handle the IndexError\n            print(f\"An IndexError occurred when idx={idx}\")\n            return 0, 0\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:37.621337Z","iopub.execute_input":"2023-11-19T15:48:37.621725Z","iopub.status.idle":"2023-11-19T15:48:37.629087Z","shell.execute_reply.started":"2023-11-19T15:48:37.621698Z","shell.execute_reply":"2023-11-19T15:48:37.628149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generative_dataset = GenerativeJawDataset()\ntest_dataset = TestJawDataset()\nreal_dataset = RealJawDataset()\ntraining_dataset = TrainingDataset()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:39.561612Z","iopub.execute_input":"2023-11-19T15:48:39.561957Z","iopub.status.idle":"2023-11-19T15:48:39.572954Z","shell.execute_reply.started":"2023-11-19T15:48:39.561928Z","shell.execute_reply":"2023-11-19T15:48:39.572226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(training_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:39.952451Z","iopub.execute_input":"2023-11-19T15:48:39.952716Z","iopub.status.idle":"2023-11-19T15:48:39.959489Z","shell.execute_reply.started":"2023-11-19T15:48:39.952694Z","shell.execute_reply":"2023-11-19T15:48:39.958393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(training_dataset)):\n    gen, re = training_dataset[i]\n    print(\"generative \" + str(\"lower\" if gen[3] == 1 else \"upper\") + \" + real \" + str(\"lower\" if re[3] == 1 else \"upper\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:40.833708Z","iopub.execute_input":"2023-11-19T15:48:40.834346Z","iopub.status.idle":"2023-11-19T15:48:40.927807Z","shell.execute_reply.started":"2023-11-19T15:48:40.834318Z","shell.execute_reply":"2023-11-19T15:48:40.926949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Real Data","metadata":{}},{"cell_type":"code","source":"data = real_dataset[1]\nvisualize_point_cloud(data[0], data[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:57.469289Z","iopub.execute_input":"2023-11-19T15:48:57.469658Z","iopub.status.idle":"2023-11-19T15:48:57.517839Z","shell.execute_reply.started":"2023-11-19T15:48:57.469631Z","shell.execute_reply":"2023-11-19T15:48:57.516999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Real Annotated Test Data","metadata":{}},{"cell_type":"code","source":"data = test_dataset[0]\n\nvisualize_point_cloud(data[0], data[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:58.665925Z","iopub.execute_input":"2023-11-19T15:48:58.666297Z","iopub.status.idle":"2023-11-19T15:48:58.710400Z","shell.execute_reply.started":"2023-11-19T15:48:58.666269Z","shell.execute_reply":"2023-11-19T15:48:58.709595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Generative Jaw Data With Annotations","metadata":{}},{"cell_type":"code","source":"data = generative_dataset[16]\nvisualize_point_cloud(data[0], data[1], generative=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:48:59.452363Z","iopub.execute_input":"2023-11-19T15:48:59.452660Z","iopub.status.idle":"2023-11-19T15:48:59.497818Z","shell.execute_reply.started":"2023-11-19T15:48:59.452637Z","shell.execute_reply":"2023-11-19T15:48:59.497023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model: PointNet","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/yanx27/Pointnet_Pointnet2_pytorch.git","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:49:04.412624Z","iopub.execute_input":"2023-11-19T15:49:04.413378Z","iopub.status.idle":"2023-11-19T15:49:09.257651Z","shell.execute_reply.started":"2023-11-19T15:49:04.413346Z","shell.execute_reply":"2023-11-19T15:49:09.256531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradReverse(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output.neg()\n\ndef GRL(x):\n    return GradReverse.apply(x)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:49:09.259570Z","iopub.execute_input":"2023-11-19T15:49:09.259858Z","iopub.status.idle":"2023-11-19T15:49:09.265932Z","shell.execute_reply.started":"2023-11-19T15:49:09.259832Z","shell.execute_reply":"2023-11-19T15:49:09.265109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.utils.data\nfrom torch.autograd import Variable\nimport numpy as np\nimport torch.nn.functional as F\n\n\nclass STN3d(nn.Module):\n    def __init__(self, channel):\n        super(STN3d, self).__init__()\n        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 9)\n        self.relu = nn.ReLU()\n\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.bn5 = nn.BatchNorm1d(256)\n\n    def forward(self, x):\n        batchsize = x.size()[0]\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = torch.max(x, 2, keepdim=True)[0]\n        x = x.view(-1, 1024)\n\n        x = F.relu(self.bn4(self.fc1(x)))\n        x = F.relu(self.bn5(self.fc2(x)))\n        x = self.fc3(x)\n\n        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(\n            batchsize, 1)\n        if x.is_cuda:\n            iden = iden.cuda()\n        x = x + iden\n        x = x.view(-1, 3, 3)\n        return x\n\n\nclass STNkd(nn.Module):\n    def __init__(self, k=64):\n        super(STNkd, self).__init__()\n        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, k * k)\n        self.relu = nn.ReLU()\n\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.bn5 = nn.BatchNorm1d(256)\n\n        self.k = k\n\n    def forward(self, x):\n        batchsize = x.size()[0]\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = torch.max(x, 2, keepdim=True)[0]\n        x = x.view(-1, 1024)\n\n        x = F.relu(self.bn4(self.fc1(x)))\n        x = F.relu(self.bn5(self.fc2(x)))\n        x = self.fc3(x)\n\n        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1, self.k * self.k).repeat(\n            batchsize, 1)\n        if x.is_cuda:\n            iden = iden.cuda()\n        x = x + iden\n        x = x.view(-1, self.k, self.k)\n        return x\n\ndef feature_transform_reguliarzer(trans):\n    d = trans.size()[1]\n    I = torch.eye(d)[None, :, :]\n    if trans.is_cuda:\n        I = I.cuda()\n    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - I, dim=(1, 2)))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:49:09.267278Z","iopub.execute_input":"2023-11-19T15:49:09.267669Z","iopub.status.idle":"2023-11-19T15:49:09.292178Z","shell.execute_reply.started":"2023-11-19T15:49:09.267638Z","shell.execute_reply":"2023-11-19T15:49:09.291353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetBackbone(nn.Module):\n    def __init__(self):\n        super(PointNetBackbone, self).__init__()\n        self.stn = STN3d(3)\n        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n        self.fstn = STNkd(k=64)\n\n    def forward(self, x):\n        B, D, N = x.size()\n        trans = self.stn(x)\n        x = x.transpose(2, 1)\n        x = torch.bmm(x, trans)\n        x = x.transpose(2, 1)\n        x = F.relu(self.bn1(self.conv1(x)))\n\n        trans_feat = self.fstn(x)\n        x = x.transpose(2, 1)\n        x = torch.bmm(x, trans_feat)\n        x = x.transpose(2, 1)\n\n        pointfeat = x\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.bn3(self.conv3(x))\n        x = torch.max(x, 2, keepdim=True)[0]\n        x = x.view(-1, 1024)\n        xx = x.view(-1, 1024, 1).repeat(1, 1, N)\n        return x, torch.cat([xx, pointfeat], 1), trans, trans_feat\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T15:49:09.294323Z","iopub.execute_input":"2023-11-19T15:49:09.294860Z","iopub.status.idle":"2023-11-19T15:49:09.306432Z","shell.execute_reply.started":"2023-11-19T15:49:09.294834Z","shell.execute_reply":"2023-11-19T15:49:09.305667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetSegHead(nn.Module):\n    def __init__(self, backbone=None, part_num=4, grl=None):\n        super(PointNetSegHead, self).__init__()\n\n        self.feat = backbone\n        \n        self.head = nn.Sequential(\n            nn.Conv1d(1088, 512, kernel_size=1),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Conv1d(512, 256, kernel_size=1),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Conv1d(256, 128, kernel_size=1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, part_num, kernel_size=1)\n        )\n\n    def forward(self, combined_feature):\n        x = self.head(combined_feature)\n        x = x.transpose(2, 1)\n        x = F.log_softmax(x, dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:06:27.489917Z","iopub.execute_input":"2023-11-19T16:06:27.490818Z","iopub.status.idle":"2023-11-19T16:06:27.499159Z","shell.execute_reply.started":"2023-11-19T16:06:27.490774Z","shell.execute_reply":"2023-11-19T16:06:27.498277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetDomainAdaptationModel(nn.Module):\n    def __init__(self, m=CLASSESS_CNT):\n        super(PointNetDomainAdaptationModel, self).__init__()\n\n        self.m = m\n\n        # Define the Fundamentals\n        self.backbone = PointNetBackbone()\n        self.segmentation_head = PointNetSegHead(part_num=self.m)\n\n    def forward(self, x1, x2=None):\n        x1_global, x_combined, trans, seg_trans_feat = self.backbone(x1)\n        seg_hat = self.segmentation_head(x_combined)\n        if x2 is not None:\n            x2_global, _, _, _ = self.backbone(x2)\n            return seg_hat, seg_trans_feat, x1_global, x2_global\n        else:\n            return seg_hat, trans, seg_trans_feat","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:38.180896Z","iopub.execute_input":"2023-11-19T16:10:38.181274Z","iopub.status.idle":"2023-11-19T16:10:38.188627Z","shell.execute_reply.started":"2023-11-19T16:10:38.181247Z","shell.execute_reply":"2023-11-19T16:10:38.187700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finally","metadata":{}},{"cell_type":"code","source":"model = PointNetDomainAdaptationModel(m=CLASSESS_CNT).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:41.189925Z","iopub.execute_input":"2023-11-19T16:10:41.190323Z","iopub.status.idle":"2023-11-19T16:10:41.233790Z","shell.execute_reply.started":"2023-11-19T16:10:41.190294Z","shell.execute_reply":"2023-11-19T16:10:41.232884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of trainable parameters\nnum_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(\"Number of trainable parameters:\", num_parameters)\n\n# Calculate the model size in megabytes (MB)\nmodel_size_mb = sum(p.numel() for p in model.parameters()) * 4 / (1024 ** 2)  # assuming 4 bytes per parameter\nprint(\"Model size:\", model_size_mb, \"MB\")\n\n# Calculate the size of the model's state dictionary in megabytes (MB)\nmodel_state_dict_size_mb = sum(p.numel() for p in model.state_dict().values()) * 4 / (1024 ** 2)\nprint(\"Model state dictionary size:\", model_state_dict_size_mb, \"MB\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:41.468844Z","iopub.execute_input":"2023-11-19T16:10:41.469218Z","iopub.status.idle":"2023-11-19T16:10:41.478167Z","shell.execute_reply.started":"2023-11-19T16:10:41.469189Z","shell.execute_reply":"2023-11-19T16:10:41.477292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointNetSegLoss(torch.nn.Module):\n    def __init__(self, mat_diff_loss_scale=0.001):\n        super(PointNetSegLoss, self).__init__()\n        self.mat_diff_loss_scale = mat_diff_loss_scale\n        \n        self.cross_entropy_loss = nn.CrossEntropyLoss()\n\n    def forward(self, pred, target, trans_feat):\n        loss = self.cross_entropy_loss(pred, target)\n        mat_diff_loss = feature_transform_reguliarzer(trans_feat)\n        total_loss = loss + mat_diff_loss * self.mat_diff_loss_scale\n        return total_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:41.816296Z","iopub.execute_input":"2023-11-19T16:10:41.816945Z","iopub.status.idle":"2023-11-19T16:10:41.823354Z","shell.execute_reply.started":"2023-11-19T16:10:41.816916Z","shell.execute_reply":"2023-11-19T16:10:41.822444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, target=1):\n        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n        loss_contrastive = torch.mean((1 - target) * torch.pow(euclidean_distance, 2) +\n                                      (target) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n\n        return loss_contrastive","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:42.172352Z","iopub.execute_input":"2023-11-19T16:10:42.173088Z","iopub.status.idle":"2023-11-19T16:10:42.179438Z","shell.execute_reply.started":"2023-11-19T16:10:42.173056Z","shell.execute_reply":"2023-11-19T16:10:42.178487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TotalLoss(nn.Module):\n    def __init__(self, mat_diff_loss_scale=0.001):\n        super(TotalLoss, self).__init__()\n        self.mat_diff_loss_scale = mat_diff_loss_scale\n        \n        # Lossess\n        self.seg_loss = PointNetSegLoss()  \n        self.con_loss = ContrastiveLoss()\n\n    def forward(self, seg_hat, seg, seg_trans_feat, x1_global, x2_global):        \n        segmentation_loss = self.seg_loss(seg_hat, seg, seg_trans_feat)\n        contrastive_loss = self.con_loss(x1_global, x2_global)\n        #total_loss = segmentation_loss + contrastive_loss #### TURNING D.A OFF\n        total_loss = segmentation_loss\n        total_loss = total_loss.mean()\n        return total_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:32:00.323448Z","iopub.execute_input":"2023-11-19T16:32:00.324537Z","iopub.status.idle":"2023-11-19T16:32:00.660057Z","shell.execute_reply.started":"2023-11-19T16:32:00.324490Z","shell.execute_reply":"2023-11-19T16:32:00.658942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_iou(predictions, targets):\n    intersection = (predictions & targets).sum()\n    union = (predictions | targets).sum()\n    iou = intersection / union\n    return iou","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:43.005373Z","iopub.execute_input":"2023-11-19T16:10:43.005743Z","iopub.status.idle":"2023-11-19T16:10:43.010782Z","shell.execute_reply.started":"2023-11-19T16:10:43.005715Z","shell.execute_reply":"2023-11-19T16:10:43.009913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:10:58.995357Z","iopub.execute_input":"2023-11-19T16:10:58.995721Z","iopub.status.idle":"2023-11-19T16:10:59.000075Z","shell.execute_reply.started":"2023-11-19T16:10:58.995686Z","shell.execute_reply":"2023-11-19T16:10:58.999055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"highest_iou = 0.0\ndef test(dataloader, model, loss_function):\n    global highest_iou\n    model.eval()\n    total_iou = 0.0\n    total_batches = len(dataloader)\n    \n    with torch.no_grad():\n        for batch, data in enumerate(tqdm(dataloader)):\n            pointcloud, label, d = (data[0].permute(0, 2, 1)).to(device), data[1].to(device), data[2].to(device)\n\n            # Get Scores\n            seg_hat, seg_trans, seg_trans_feat = model(pointcloud)\n\n            predicted = torch.argmax(seg_hat, dim=2)\n\n            # Calculate the IoU score for this batch\n            iou = calculate_iou(predicted, label)\n\n            total_iou += iou.item()\n            \n            # Clean memory\n            del pointcloud\n            del label\n            del seg_hat\n            del seg_trans\n            del seg_trans_feat\n            del iou\n            del predicted\n            gc.collect()\n            torch.cuda.empty_cache()\n            \n    average_iou = total_iou / total_batches\n    if average_iou >= highest_iou:\n        highest_iou = average_iou\n        torch.save(model.state_dict(), \"/kaggle/working/model_state_highest.pth\")\n    print(\"Average IoU: \" + str(average_iou))\n    print(\"\")\n    print(\"Highest IoU: \" + str(highest_iou))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:12:21.915563Z","iopub.execute_input":"2023-11-19T16:12:21.916415Z","iopub.status.idle":"2023-11-19T16:12:21.925388Z","shell.execute_reply.started":"2023-11-19T16:12:21.916383Z","shell.execute_reply":"2023-11-19T16:12:21.924433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, optimizer, loss_function):\n    torch.cuda.empty_cache()\n    size = len(dataloader.dataset)\n    model.train()\n    loss_tot = 0.0\n    num = 0\n    for batch, data in enumerate(tqdm(dataloader)):\n        data0, data1 = data\n        pointcloud0, label0, d0, l0 = (data0[0].permute(0, 2, 1)).to(device), data0[1].to(device), data0[2].to(device), data0[3].to(device)\n        pointcloud1, label1, d1, l1 = (data1[0].permute(0, 2, 1)).to(device), data1[1].to(device), data1[2].to(device), data1[3].to(device)\n    \n        # Zeroing the gradients\n        optimizer.zero_grad()\n\n        number_of_parts = CLASSESS_CNT\n        seg0 = torch.nn.functional.one_hot(label0, number_of_parts).type(torch.FloatTensor).to(device)\n        seg1 = torch.nn.functional.one_hot(label1, number_of_parts).type(torch.FloatTensor).to(device)\n\n        # Get Scores\n        seg_hat, seg_trans_feat, x1_global, x2_global = model(pointcloud0, pointcloud1)\n\n        # Calculate Loss\n        loss = loss_function(seg_hat, seg0, seg_trans_feat, x1_global, x2_global)\n\n        # Backpropagation\n        loss.backward()\n\n        # Update\n        optimizer.step()\n        \n        loss_tot += loss.item()\n        num += 1\n        \n        # Clean memory\n        del data0\n        del data1\n        del pointcloud0\n        del pointcloud1\n        del label0\n        del label1\n        del d0\n        del d1\n        del l0\n        del l1\n        del number_of_parts\n        del seg0\n        del seg1\n        del seg_hat\n        del seg_trans_feat\n        del x1_global\n        del x2_global\n        del loss\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n    # loss_tot /= num\n    print(f'training loss: {(loss_tot):>0.5f}')\n    return loss_tot","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:12:22.228694Z","iopub.execute_input":"2023-11-19T16:12:22.229085Z","iopub.status.idle":"2023-11-19T16:12:22.240902Z","shell.execute_reply.started":"2023-11-19T16:12:22.229055Z","shell.execute_reply":"2023-11-19T16:12:22.239944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_single_test_data(dataloader, model):\n    model.eval()\n    with torch.no_grad():\n        for batch, data in enumerate(tqdm(dataloader)):\n            pointcloud, label, d = (data[0].permute(0, 2, 1)).to(device), data[1].long().to(device), data[2].long().to(device)\n            # Get Scores\n            seg_hat,_,_ = model(pointcloud)\n            predicted = torch.argmax(seg_hat, dim=2).cpu()\n            \n            pointcloud_2 = pointcloud.clone().permute(0,2,1).cpu()\n            visualize_point_cloud(pointcloud_2[0], predicted[0])\n            break","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:15:13.513808Z","iopub.execute_input":"2023-11-19T16:15:13.514536Z","iopub.status.idle":"2023-11-19T16:15:13.521605Z","shell.execute_reply.started":"2023-11-19T16:15:13.514500Z","shell.execute_reply":"2023-11-19T16:15:13.520579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Hyperparameters\nepochs = 500\nbatch_size = 50\nlearning_rate = 1e-3\nmomentum=0.9\nweight_decay=0.5\n\n# Dataloader\ntraining_data_loader = DataLoader(training_dataset, batch_size, shuffle = True)\ntesting_dataloader = DataLoader(test_dataset, batch_size, shuffle = False)\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n# Loss \nloss_function = TotalLoss(mat_diff_loss_scale=0.001).to(device)\n\n# Scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=1e-5, eps=1e-08)\n\n# Training\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loss = train(training_data_loader, model, optimizer, loss_function)\n    test(testing_dataloader, model,loss_function )\n    scheduler.step(train_loss)\n    torch.save(model.state_dict(), \"/kaggle/working/model_state.pth\")\nprint(\"Done!\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Best Predictions","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/model_state_highest.pth\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:14:39.042815Z","iopub.execute_input":"2023-11-19T16:14:39.043560Z","iopub.status.idle":"2023-11-19T16:14:39.078753Z","shell.execute_reply.started":"2023-11-19T16:14:39.043524Z","shell.execute_reply":"2023-11-19T16:14:39.077885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_single_test_data(testing_dataloader, model)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:15:18.485496Z","iopub.execute_input":"2023-11-19T16:15:18.485875Z","iopub.status.idle":"2023-11-19T16:15:18.541121Z","shell.execute_reply.started":"2023-11-19T16:15:18.485845Z","shell.execute_reply":"2023-11-19T16:15:18.540205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = test_dataset[0]\nvisualize_point_cloud(data[0], data[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-19T16:15:26.544090Z","iopub.execute_input":"2023-11-19T16:15:26.545014Z","iopub.status.idle":"2023-11-19T16:15:26.593905Z","shell.execute_reply.started":"2023-11-19T16:15:26.544956Z","shell.execute_reply":"2023-11-19T16:15:26.593025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}